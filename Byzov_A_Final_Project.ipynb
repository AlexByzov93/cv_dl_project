{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4GpRq1k941p"
      },
      "source": [
        "# Deep Sort Implementation\n",
        "\n",
        "This notebook is dedicated to implementation of deep sort algorithm from [the original repository](https://github.com/nwojke/deep_sort). This implementation will be subjected to several changes during this project:\n",
        "\n",
        "- Adding 3 additional detectors\n",
        "- Adding 3 additional REID algorithms\n",
        "- Adding 1 additional segmentation algorithm\n",
        "\n",
        "This algorithm will be checked on the following data from MOT challenge:\n",
        "\n",
        "- TUD-Campus\n",
        "- TUD-Stadtmitte\n",
        "- KITTI-17\n",
        "- PETS09-S2L1 from MOT15\n",
        "- MOT16-09, MOT16-11 from MOT16\n",
        "\n",
        "\n",
        "Since one of the requirements of the project is to implement it in the Google Colab Notebook, I decided to move the main function from the repository into Google Colab in order to make visible any changes to the original algorithm.\n",
        "\n",
        "## Project Structure\n",
        "\n",
        "This project has the following file structure:\n",
        "\n",
        "- `application_util`, `deep_sort`, `tools` folders contain original and modified code for deep sort\n",
        "- `deep_sort_app.py` file contains functions for running the whole model\n",
        "- `data` folder contains data from MOT challenges\n",
        "- `resources` folder with `detections` and `networks` subfolders which contain object detections, features for REID and models for extracting features.\n",
        "- `Byzov A - Final Project.ipynb` notebook with the detailed report on creation and development of the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzpO3hWaO1p7"
      },
      "source": [
        "## Step 1. Preparing a Google Colab folder for deep sort algorithm\n",
        "\n",
        "In this step I move to a folder in Google Colab with necessary files. For this commit files are already there, but for the final commit I will create a script to copy these files from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRKbLbts94Bb",
        "outputId": "6f22a485-85ed-4f18-d48c-0ee58df454ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arAun6lCPAPE",
        "outputId": "bc2f83c6-48b1-4ffe-85cb-bbaa84e2fb80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CV_DL_Project\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/CV_DL_Project'\n",
        "%cd $DATA_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGvahxWvPhdO"
      },
      "source": [
        "## Step 2. Preparing an original deep sort implementation for Google Colab\n",
        "\n",
        "The original deep sort required minimal changes to make it operable on GitHub. These changes are:\n",
        "\n",
        "- Adding lines to `linear_assignment.py` and `generate_detection.py` to make them work with tensorflow2;\n",
        "- Changing `image_viewer.py` to make it work on Google Colab, i.e., using `cv2_imshow()` instead of `cv2.imshow()`;\n",
        "- Changing name of the `run` function in `deep_sort_app.py` to `deep_sort_run` for ease of understanding\n",
        "- Adding a new argument `custom_detection` which allows to switch on or off our future custom detection and reidentification models. For now, it is used as `False`\n",
        "\n",
        "Now, let's check if it works. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA-x2mqlPYc4",
        "outputId": "c714a288-343d-4aeb-c97d-b3b7368fe9ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CV_DL_Project/torchreid/metrics/rank.py:12: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  'Cython evaluation (very fast so highly recommended) is '\n"
          ]
        }
      ],
      "source": [
        "from deep_sort_app import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4JwHTkPR9WK"
      },
      "outputs": [],
      "source": [
        "deep_sort_run(\n",
        "    sequence_dir=\"./data/MOT16/test/MOT16-06\",\n",
        "    detection_file=\"./resources/detections/MOT16_POI_test/MOT16-06.npy\",\n",
        "    output_file=\"./tmp/hypotheses.txt\",\n",
        "    min_confidence=0.8,\n",
        "    nms_max_overlap=1.0,\n",
        "    min_detection_height=0,\n",
        "    max_cosine_distance=0.2,\n",
        "    nn_budget=None,\n",
        "    display=False,\n",
        "    custom_detection=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsrC_KtlDtFb"
      },
      "source": [
        "## Step 3. Adding new object detection and reidentification algorithms\n",
        "\n",
        "Original deep sort does not run in real time, it actually precalculates values for detection boxes and features REID and stores in `.npy` file. Since we want to create more or less real-time deep_sort implementation, we need to change `deep_sort_app.py` in such a way that it uses our own detections.\n",
        "\n",
        "Detections have `N x 138` format, where the first ten observations are:\n",
        "- Frame\n",
        "- Object\n",
        "- Bounding boxes\n",
        "- Confidence Intervals\n",
        "- X, Y, Z coordinates (irrelevant for 2D, needs to be kept at -1)\n",
        "- Features for reidentification\n",
        "\n",
        "We are going to change algorithms that produce bounding boxes and features for reidentification. \n",
        "\n",
        "For finding bounding boxes for images we are going to use a family of models `EfficientDet Lite`. These models are quite fast and allow us to easily extract bounding boxes in x1, x2, y1, y2 format. This format is good for finding image patches for feature extraction with reidentification models. The current implementation allows to use all models from the `EfficientDet Lite` family: `lite0`, `lite1`, `lite2`, `lite3`, `lite4`. These models differ in a number of parameters and their confidence (bigger model is slower, but more precise). While this format is good for image detection, it needs to be changed into to bb_left, bb_top, width, height. Credits to [Google](https://tfhub.dev/tensorflow/efficientdet/lite1/detection/1)\n",
        "\n",
        "For extracting feature for reidentification we are going to use a more precise framework from torchreid. This framework extracts different number of features from each image patch (for example, resnet18 extracts 512 features and mobilenetv2_x1_0 extracts 1280 features). This framework supports huge number of models [read more here](https://kaiyangzhou.github.io/deep-person-reid/pkg/models.html). I recommend to use the following set of models: `resnet18` or these and other mobile models (i.e., `nasnetamobile`, `mobilenetv2_x1_0`, `mobilenetv2_x1_4`, `shufflenet_v2_x0_5`). Credits to [Dr. Kaiyang Zhou](https://kaiyangzhou.github.io/).\n",
        "\n",
        "Let's see how it works on one image before we add it into `deep_sort_app.py` \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ed9pWec8RsP",
        "outputId": "a0c547b6-7280-4cea-f959-32b64f329987"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CV_DL_Project/torchreid/metrics/rank.py:12: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  'Cython evaluation (very fast so highly recommended) is '\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchreid.utils.feature_extractor import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uxvy2RQTTgc"
      },
      "source": [
        "Before we could use the whole setup, we also need to use some parts of torchreid and put into a project folder. To do it, you can use the following script, but you probably need to change some parts of the absolute path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM1rYGROTTPP",
        "outputId": "bfd9a75f-aa71-4b4f-8e5b-8df459a36bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-person-reid'...\n",
            "remote: Enumerating objects: 9854, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 9854 (delta 0), reused 0 (delta 0), pack-reused 9850\u001b[K\n",
            "Receiving objects: 100% (9854/9854), 9.57 MiB | 7.73 MiB/s, done.\n",
            "Resolving deltas: 100% (7285/7285), done.\n",
            "Checking out files: 100% (155/155), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KaiyangZhou/deep-person-reid.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u-kYKovETphf"
      },
      "outputs": [],
      "source": [
        "!mv /content/drive/MyDrive/CV_DL_Project/deep-person-reid/torchreid /content/drive/MyDrive/CV_DL_Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70KEMsYrT3MN",
        "outputId": "9a5c323b-338e-42ec-8cc4-7d65448ac137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/CV_DL_Project/deep-person-reid': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/drive/MyDrive/CV_DL_Project/deep-person-reid/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zqZwBifobDaT"
      },
      "outputs": [],
      "source": [
        "def extract_patches(image, boxes_scores):\n",
        "    \"\"\"\n",
        "    extract patches from an image with box scores\n",
        "    \"\"\"\n",
        "    boxes_int = boxes_scores[:4]\n",
        "    patches = np.asarray([image[x1:x2, y1:y2] for x1, y1, x2, y2, _ in np.int32(boxes_scores)])\n",
        "    return patches\n",
        "\n",
        "def create_object_detector(model_det):\n",
        "    \"\"\"\n",
        "    downloads object detector and loads it into a program, creates a specific transformation for images for object detection\n",
        "    \"\"\"\n",
        "    object_detector_model = f\"https://tfhub.dev/tensorflow/efficientdet/{model_det}/detection/1\"\n",
        "    object_detector = hub.load(object_detector_model)\n",
        "\n",
        "    def detection_img_transformer(image):\n",
        "        return tf.image.convert_image_dtype(image, tf.uint8)[tf.newaxis, ...]\n",
        "\n",
        "    return object_detector, detection_img_transformer\n",
        "\n",
        "def create_reid_extractor(model_reid):\n",
        "    \"\"\"\n",
        "    creates feature extractor from image with different models trained for REID task\n",
        "    \"\"\"\n",
        "    reid_feature_extractor = FeatureExtractor(model_reid)\n",
        "    \n",
        "    return reid_feature_extractor\n",
        "\n",
        "def create_custom_detections(image, frame_idx, object_detector, detection_img_transformer, reid_feature_extractor, conf_level=0.5):\n",
        "    \"\"\"\n",
        "    creates a detection_mat np array in a similar to original format where first ten columns are from MOT challenge format and other are for features\n",
        "    \"\"\"\n",
        "    det_image = detection_img_transformer(image)\n",
        "    boxes, scores, _, _ = object_detector(det_image)\n",
        "\n",
        "    boxes_scores = np.dstack((boxes, scores))\n",
        "    boxes_scores = boxes_scores[0][boxes_scores[0][:, 4] >= conf_level]\n",
        "\n",
        "    box_rows, _ = boxes_scores.shape\n",
        "\n",
        "    patches = extract_patches(image, boxes_scores)\n",
        "\n",
        "    boxes_scores[:, 2] = boxes_scores[:, 2] - boxes_scores[:, 0]\n",
        "    boxes_scores[:, 3] = boxes_scores[:, 3] - boxes_scores[:, 1]\n",
        "\n",
        "    features = np.array([reid_feature_extractor(img).cpu().numpy() for img in patches])\n",
        "    features = features.reshape(box_rows, features.shape[2])\n",
        "\n",
        "    detection_mat = np.concatenate(\n",
        "        (\n",
        "            np.repeat(frame_idx, box_rows).reshape(box_rows, 1),\n",
        "            np.repeat(-1, box_rows).reshape(box_rows, 1),\n",
        "            boxes_scores,\n",
        "            np.repeat(np.array([-1, -1, -1]), box_rows).reshape(box_rows, 3),\n",
        "            features\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return detection_mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAN506r6bxw7"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('./img.jpeg', cv2.IMREAD_COLOR)\n",
        "object_detector, detection_img_transformer = create_object_detector(\"lite1\")\n",
        "reid_feature_extractor = create_reid_extractor(\"resnet18\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "didKSb5JhOp9",
        "outputId": "85eb8738-f849-40cb-d31d-f1c17608e50d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "detection_mat = create_custom_detections(image, 1, object_detector, detection_img_transformer, reid_feature_extractor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCFTo6XdNiL1"
      },
      "source": [
        "## Step 4. Updating deep_sort_run function\n",
        "\n",
        "Now, it is important to move our functionality into `deep_sort_app.py` in such a way that any user could easily fire up `deep_sort_run` with custom real time object detection and reidentification algorithms.\n",
        "\n",
        "To do that I added several additional arguments into `deep_sort_run`:\n",
        "\n",
        "- `custom_detection` - a flag that allows switch on switch off a custom detection\n",
        "- `model_det` - a string parameter that allows us to specify a model from EfficientDet family. Uses _lite0_ by default\n",
        "- `model_reid` - a string parameter that allows us to specify a model from a huge number of models used in torchreid. Uses _resnet18_ by default.\n",
        "\n",
        "For this code to work, you need to use GPU runtime in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SuyL8NpQbTu"
      },
      "outputs": [],
      "source": [
        "\n",
        "deep_sort_run(\n",
        "    sequence_dir=\"./data/MOT16/test/MOT16-06\",\n",
        "    detection_file=\"./resources/detections/MOT16_POI_test/MOT16-06.npy\",\n",
        "    output_file=\"./tmp/hypotheses.txt\",\n",
        "    min_confidence=0.8,\n",
        "    nms_max_overlap=1.0,\n",
        "    min_detection_height=0,\n",
        "    max_cosine_distance=0.2,\n",
        "    nn_budget=None,\n",
        "    display=False,\n",
        "    custom_detection=True,\n",
        "    model_det=\"lite0\",\n",
        "    model_reid=\"resnet18\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Byzov A - Final Project.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
